{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 â€” Feature Engineering\n",
        "\n",
        "**Objective**: Transform session-level data into customer-level features for segmentation.\n",
        "\n",
        "**Approach**:\n",
        "- Aggregate behavioral metrics per customer\n",
        "- Create booking propensity features\n",
        "- Engineer discount sensitivity indicators\n",
        "- Build customer lifetime value proxies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Load cleaned data from EDA pipeline\n",
        "eda_latest = Path('../artifacts/eda/latest/data')\n",
        "sessions_clean = pd.read_parquet(eda_latest / 'sessions_clean.parquet')\n",
        "\n",
        "print(f\"Loaded {len(sessions_clean):,} clean sessions\")\n",
        "print(f\"Unique users: {sessions_clean['user_id'].nunique():,}\")\n",
        "sessions_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Behavioral Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Session-level behavioral aggregations\n",
        "behavioral_features = sessions_clean.groupby('user_id').agg({\n",
        "    'session_id': 'nunique',  # Total sessions\n",
        "    'session_duration_sec': ['mean', 'std', 'max'],\n",
        "    'page_clicks': ['mean', 'std', 'max', 'sum'],\n",
        "    'flight_booked': ['mean', 'sum'],\n",
        "    'hotel_booked': ['mean', 'sum'],\n",
        "    'cancellation': ['mean', 'sum'],\n",
        "    'flight_discount': 'mean',\n",
        "    'hotel_discount': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "# Flatten column names\n",
        "behavioral_features.columns = ['_'.join(col).strip() for col in behavioral_features.columns]\n",
        "behavioral_features = behavioral_features.rename(columns={\n",
        "    'session_id_nunique': 'n_sessions',\n",
        "    'flight_booked_mean': 'flight_booking_rate',\n",
        "    'hotel_booked_mean': 'hotel_booking_rate',\n",
        "    'cancellation_mean': 'cancellation_rate',\n",
        "    'flight_discount_mean': 'flight_discount_rate',\n",
        "    'hotel_discount_mean': 'hotel_discount_rate'\n",
        "})\n",
        "\n",
        "print(f\"Behavioral features shape: {behavioral_features.shape}\")\n",
        "behavioral_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Booking Value Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Booking value aggregations (only for customers who booked)\n",
        "booking_features = sessions_clean.groupby('user_id').agg({\n",
        "    'flight_discount_amount': ['mean', 'sum', 'count'],\n",
        "    'hotel_discount_amount': ['mean', 'sum', 'count'],\n",
        "    'base_fare_usd': ['mean', 'sum', 'count'],\n",
        "    'hotel_per_room_usd': ['mean', 'sum', 'count'],\n",
        "    'nights': ['mean', 'sum'],\n",
        "    'rooms': ['mean', 'sum'],\n",
        "    'seats': ['mean', 'sum'],\n",
        "    'checked_bags': ['mean', 'sum']\n",
        "}).round(2)\n",
        "\n",
        "# Flatten column names\n",
        "booking_features.columns = ['_'.join(col).strip() for col in booking_features.columns]\n",
        "\n",
        "# Fill NaN with 0 (customers who didn't book)\n",
        "booking_features = booking_features.fillna(0)\n",
        "\n",
        "print(f\"Booking features shape: {booking_features.shape}\")\n",
        "booking_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customer Lifetime Value Proxies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate CLV proxies\n",
        "clv_features = pd.DataFrame(index=behavioral_features.index)\n",
        "\n",
        "# Total revenue proxy\n",
        "clv_features['total_flight_value'] = booking_features['base_fare_usd_sum']\n",
        "clv_features['total_hotel_value'] = booking_features['hotel_per_room_usd_sum'] * booking_features['nights_sum']\n",
        "clv_features['total_booking_value'] = clv_features['total_flight_value'] + clv_features['total_hotel_value']\n",
        "\n",
        "# Engagement metrics\n",
        "clv_features['avg_session_value'] = clv_features['total_booking_value'] / behavioral_features['n_sessions']\n",
        "clv_features['engagement_score'] = (\n",
        "    behavioral_features['n_sessions'] * \n",
        "    behavioral_features['page_clicks_mean'] * \n",
        "    behavioral_features['session_duration_sec_mean'] / 3600  # Convert to hours\n",
        ").round(2)\n",
        "\n",
        "# Discount sensitivity\n",
        "clv_features['discount_sensitivity'] = (\n",
        "    behavioral_features['flight_discount_rate'] + \n",
        "    behavioral_features['hotel_discount_rate']\n",
        ") / 2\n",
        "\n",
        "# Fill NaN/inf with 0\n",
        "clv_features = clv_features.fillna(0).replace([np.inf, -np.inf], 0)\n",
        "\n",
        "print(f\"CLV features shape: {clv_features.shape}\")\n",
        "clv_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customer Segmentation Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create customer type indicators\n",
        "segmentation_features = pd.DataFrame(index=behavioral_features.index)\n",
        "\n",
        "# Customer type based on booking behavior\n",
        "segmentation_features['flight_only_customer'] = (\n",
        "    (behavioral_features['flight_booking_rate'] > 0) & \n",
        "    (behavioral_features['hotel_booking_rate'] == 0)\n",
        ").astype(int)\n",
        "\n",
        "segmentation_features['hotel_only_customer'] = (\n",
        "    (behavioral_features['hotel_booking_rate'] > 0) & \n",
        "    (behavioral_features['flight_booking_rate'] == 0)\n",
        ").astype(int)\n",
        "\n",
        "segmentation_features['full_trip_customer'] = (\n",
        "    (behavioral_features['flight_booking_rate'] > 0) & \n",
        "    (behavioral_features['hotel_booking_rate'] > 0)\n",
        ").astype(int)\n",
        "\n",
        "segmentation_features['browser_only'] = (\n",
        "    (behavioral_features['flight_booking_rate'] == 0) & \n",
        "    (behavioral_features['hotel_booking_rate'] == 0)\n",
        ").astype(int)\n",
        "\n",
        "# Frequency segments\n",
        "session_quartiles = behavioral_features['n_sessions'].quantile([0.25, 0.5, 0.75])\n",
        "segmentation_features['frequency_segment'] = pd.cut(\n",
        "    behavioral_features['n_sessions'],\n",
        "    bins=[0, session_quartiles[0.25], session_quartiles[0.5], session_quartiles[0.75], np.inf],\n",
        "    labels=['Low', 'Medium', 'High', 'Very High']\n",
        ")\n",
        "\n",
        "# Value segments\n",
        "value_quartiles = clv_features['total_booking_value'].quantile([0.25, 0.5, 0.75])\n",
        "segmentation_features['value_segment'] = pd.cut(\n",
        "    clv_features['total_booking_value'],\n",
        "    bins=[0, value_quartiles[0.25], value_quartiles[0.5], value_quartiles[0.75], np.inf],\n",
        "    labels=['Low', 'Medium', 'High', 'Very High']\n",
        ")\n",
        "\n",
        "print(f\"Segmentation features shape: {segmentation_features.shape}\")\n",
        "segmentation_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combine All Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine all feature sets\n",
        "customer_features = pd.concat([\n",
        "    behavioral_features,\n",
        "    booking_features,\n",
        "    clv_features,\n",
        "    segmentation_features\n",
        "], axis=1)\n",
        "\n",
        "# Add user demographics\n",
        "user_demographics = sessions_clean.groupby('user_id')[[\n",
        "    'gender', 'married', 'has_children', 'home_country', 'home_city'\n",
        "]].first()\n",
        "\n",
        "customer_features = customer_features.join(user_demographics)\n",
        "\n",
        "print(f\"Final customer features shape: {customer_features.shape}\")\n",
        "print(f\"Features: {list(customer_features.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Analysis & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature correlation analysis\n",
        "numeric_features = customer_features.select_dtypes(include=[np.number])\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "correlation_matrix = numeric_features.corr()\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# High correlation pairs\n",
        "high_corr = correlation_matrix.abs() > 0.8\n",
        "high_corr_pairs = []\n",
        "for i in range(len(high_corr.columns)):\n",
        "    for j in range(i+1, len(high_corr.columns)):\n",
        "        if high_corr.iloc[i, j]:\n",
        "            high_corr_pairs.append((\n",
        "                high_corr.columns[i], \n",
        "                high_corr.columns[j], \n",
        "                correlation_matrix.iloc[i, j]\n",
        "            ))\n",
        "\n",
        "print(\"High correlation pairs (>0.8):\")\n",
        "for pair in high_corr_pairs:\n",
        "    print(f\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature distributions\n",
        "key_features = [\n",
        "    'n_sessions', 'flight_booking_rate', 'hotel_booking_rate', \n",
        "    'total_booking_value', 'engagement_score', 'discount_sensitivity'\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    if feature in numeric_features.columns:\n",
        "        axes[i].hist(numeric_features[feature].dropna(), bins=30, alpha=0.7)\n",
        "        axes[i].set_title(f'{feature} Distribution')\n",
        "        axes[i].set_xlabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save customer features\n",
        "output_dir = Path('../artifacts/features')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Reset index to include user_id as column\n",
        "customer_features_export = customer_features.reset_index()\n",
        "\n",
        "# Save as parquet and CSV\n",
        "customer_features_export.to_parquet(output_dir / 'customer_features.parquet', index=False)\n",
        "customer_features_export.to_csv(output_dir / 'customer_features.csv', index=False)\n",
        "\n",
        "print(f\"âœ… Exported customer features to {output_dir}\")\n",
        "print(f\"   Shape: {customer_features_export.shape}\")\n",
        "print(f\"   Numeric features: {len(numeric_features.columns)}\")\n",
        "print(f\"   Categorical features: {len(customer_features.columns) - len(numeric_features.columns)}\")\n",
        "\n",
        "# Feature summary\n",
        "print(\"\\nðŸ“Š Feature Summary:\")\n",
        "print(customer_features_export.describe().round(2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
