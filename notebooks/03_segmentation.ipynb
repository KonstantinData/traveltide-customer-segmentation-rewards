{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 â€” Customer Segmentation\n",
        "\n",
        "**Objective**: Cluster customers into interpretable segments based on behavioral features.\n",
        "\n",
        "**Approach**:\n",
        "- Feature selection and scaling\n",
        "- Optimal cluster number determination\n",
        "- K-means clustering with validation\n",
        "- Segment profiling and interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Load customer features\n",
        "features_path = Path('../artifacts/outputs/customer_features.parquet')\n",
        "if not features_path.exists():\n",
        "    features_path = Path('../artifacts/features/customer_features.parquet')\n",
        "\n",
        "customer_features = pd.read_parquet(features_path)\n",
        "print(f\"Loaded {len(customer_features):,} customers with {customer_features.shape[1]} features\")\n",
        "customer_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection for Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select key behavioral features for clustering\n",
        "clustering_features = [\n",
        "    'n_sessions',\n",
        "    'avg_session_duration_sec', \n",
        "    'avg_page_clicks',\n",
        "    'p_flight_booked',\n",
        "    'p_hotel_booked', \n",
        "    'p_cancellation',\n",
        "    'p_flight_discount',\n",
        "    'p_hotel_discount',\n",
        "    'avg_base_fare_usd',\n",
        "    'avg_hotel_per_room_usd',\n",
        "    'avg_nights',\n",
        "    'avg_rooms'\n",
        "]\n",
        "\n",
        "# Filter to available features\n",
        "available_features = [f for f in clustering_features if f in customer_features.columns]\n",
        "print(f\"Using {len(available_features)} features for clustering:\")\n",
        "for f in available_features:\n",
        "    print(f\"  â€¢ {f}\")\n",
        "\n",
        "# Create feature matrix\n",
        "X = customer_features[available_features].fillna(0)\n",
        "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
        "print(f\"Missing values: {X.isnull().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=available_features, index=X.index)\n",
        "\n",
        "print(\"Feature scaling completed\")\n",
        "print(f\"Scaled features mean: {X_scaled.mean(axis=0).round(3)}\")\n",
        "print(f\"Scaled features std: {X_scaled.std(axis=0).round(3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimal Number of Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Elbow method and silhouette analysis\n",
        "k_range = range(2, 11)\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "calinski_scores = []\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "    \n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
        "    calinski_scores.append(calinski_harabasz_score(X_scaled, labels))\n",
        "\n",
        "# Plot evaluation metrics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Elbow curve\n",
        "axes[0].plot(k_range, inertias, 'bo-')\n",
        "axes[0].set_title('Elbow Method')\n",
        "axes[0].set_xlabel('Number of Clusters (k)')\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Silhouette scores\n",
        "axes[1].plot(k_range, silhouette_scores, 'ro-')\n",
        "axes[1].set_title('Silhouette Score')\n",
        "axes[1].set_xlabel('Number of Clusters (k)')\n",
        "axes[1].set_ylabel('Silhouette Score')\n",
        "axes[1].grid(True)\n",
        "\n",
        "# Calinski-Harabasz scores\n",
        "axes[2].plot(k_range, calinski_scores, 'go-')\n",
        "axes[2].set_title('Calinski-Harabasz Score')\n",
        "axes[2].set_xlabel('Number of Clusters (k)')\n",
        "axes[2].set_ylabel('CH Score')\n",
        "axes[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal k\n",
        "best_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
        "best_k_calinski = k_range[np.argmax(calinski_scores)]\n",
        "\n",
        "print(f\"Best k by Silhouette Score: {best_k_silhouette} (score: {max(silhouette_scores):.3f})\")\n",
        "print(f\"Best k by Calinski-Harabasz: {best_k_calinski} (score: {max(calinski_scores):.0f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use optimal k (or default to 5)\n",
        "optimal_k = 5  # Can be adjusted based on business requirements\n",
        "\n",
        "# Final K-means clustering\n",
        "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=20)\n",
        "cluster_labels = final_kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to customer data\n",
        "customer_segments = customer_features.copy()\n",
        "customer_segments['segment'] = cluster_labels\n",
        "\n",
        "print(f\"Clustering completed with k={optimal_k}\")\n",
        "print(f\"Silhouette Score: {silhouette_score(X_scaled, cluster_labels):.3f}\")\n",
        "print(f\"Calinski-Harabasz Score: {calinski_harabasz_score(X_scaled, cluster_labels):.0f}\")\n",
        "\n",
        "# Segment sizes\n",
        "segment_sizes = pd.Series(cluster_labels).value_counts().sort_index()\n",
        "print(f\"\\nSegment sizes:\")\n",
        "for seg, size in segment_sizes.items():\n",
        "    print(f\"  Segment {seg}: {size:,} customers ({size/len(customer_segments)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segment Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create segment profiles\n",
        "segment_profiles = customer_segments.groupby('segment')[available_features].agg([\n",
        "    'mean', 'median', 'std'\n",
        "]).round(3)\n",
        "\n",
        "# Flatten column names\n",
        "segment_profiles.columns = ['_'.join(col).strip() for col in segment_profiles.columns]\n",
        "\n",
        "print(\"Segment Profiles (Mean Values):\")\n",
        "mean_cols = [col for col in segment_profiles.columns if col.endswith('_mean')]\n",
        "display_profiles = segment_profiles[mean_cols]\n",
        "display_profiles.columns = [col.replace('_mean', '') for col in display_profiles.columns]\n",
        "print(display_profiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment visualization - Feature heatmap\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.heatmap(display_profiles.T, annot=True, cmap='viridis', fmt='.2f')\n",
        "plt.title('Segment Feature Profiles (Mean Values)')\n",
        "plt.xlabel('Segment')\n",
        "plt.ylabel('Features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']\n",
        "for i in range(optimal_k):\n",
        "    mask = cluster_labels == i\n",
        "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
        "               c=colors[i], label=f'Segment {i}', alpha=0.6)\n",
        "\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "plt.title('Customer Segments in PCA Space')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segment Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segment interpretation based on key characteristics\n",
        "segment_names = {}\n",
        "segment_descriptions = {}\n",
        "\n",
        "for seg in range(optimal_k):\n",
        "    profile = display_profiles.loc[seg]\n",
        "    \n",
        "    # Analyze key characteristics\n",
        "    high_sessions = profile.get('n_sessions', 0) > display_profiles['n_sessions'].median()\n",
        "    high_flight_booking = profile.get('p_flight_booked', 0) > 0.1\n",
        "    high_hotel_booking = profile.get('p_hotel_booked', 0) > 0.1\n",
        "    high_cancellation = profile.get('p_cancellation', 0) > 0.1\n",
        "    high_discount_usage = (profile.get('p_flight_discount', 0) + profile.get('p_hotel_discount', 0)) > 0.2\n",
        "    \n",
        "    # Generate segment names and descriptions\n",
        "    if high_flight_booking and high_hotel_booking:\n",
        "        if high_sessions:\n",
        "            name = \"Frequent Full-Trip Bookers\"\n",
        "            desc = \"High-engagement customers who book both flights and hotels regularly\"\n",
        "        else:\n",
        "            name = \"Occasional Full-Trip Bookers\"\n",
        "            desc = \"Customers who book complete trips but less frequently\"\n",
        "    elif high_flight_booking and not high_hotel_booking:\n",
        "        name = \"Flight-Focused Travelers\"\n",
        "        desc = \"Primarily book flights, minimal hotel bookings\"\n",
        "    elif high_hotel_booking and not high_flight_booking:\n",
        "        name = \"Hotel-Focused Travelers\"\n",
        "        desc = \"Primarily book hotels, minimal flight bookings\"\n",
        "    elif high_sessions and not (high_flight_booking or high_hotel_booking):\n",
        "        name = \"High-Intent Browsers\"\n",
        "        desc = \"Frequent visitors with low conversion rates\"\n",
        "    else:\n",
        "        name = \"Low-Engagement Browsers\"\n",
        "        desc = \"Infrequent visitors with minimal booking activity\"\n",
        "    \n",
        "    segment_names[seg] = name\n",
        "    segment_descriptions[seg] = desc\n",
        "\n",
        "# Display segment interpretations\n",
        "print(\"=== SEGMENT INTERPRETATIONS ===\")\n",
        "for seg in range(optimal_k):\n",
        "    size = segment_sizes[seg]\n",
        "    pct = size / len(customer_segments) * 100\n",
        "    print(f\"\\nðŸŽ¯ Segment {seg}: {segment_names[seg]}\")\n",
        "    print(f\"   Size: {size:,} customers ({pct:.1f}%)\")\n",
        "    print(f\"   Description: {segment_descriptions[seg]}\")\n",
        "    \n",
        "    # Key metrics\n",
        "    profile = display_profiles.loc[seg]\n",
        "    print(f\"   Key metrics:\")\n",
        "    print(f\"     â€¢ Avg sessions: {profile.get('n_sessions', 0):.1f}\")\n",
        "    print(f\"     â€¢ Flight booking rate: {profile.get('p_flight_booked', 0):.1%}\")\n",
        "    print(f\"     â€¢ Hotel booking rate: {profile.get('p_hotel_booked', 0):.1%}\")\n",
        "    print(f\"     â€¢ Cancellation rate: {profile.get('p_cancellation', 0):.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Segmentation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = Path('../artifacts/outputs/segments')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Export segment assignments\n",
        "segment_assignments = customer_segments[['user_id', 'segment']].copy()\n",
        "segment_assignments.to_parquet(output_dir / 'segment_assignments.parquet', index=False)\n",
        "segment_assignments.to_csv(output_dir / 'segment_assignments.csv', index=False)\n",
        "\n",
        "# Export segment profiles\n",
        "segment_summary = pd.DataFrame({\n",
        "    'segment': range(optimal_k),\n",
        "    'segment_name': [segment_names[i] for i in range(optimal_k)],\n",
        "    'description': [segment_descriptions[i] for i in range(optimal_k)],\n",
        "    'size': [segment_sizes[i] for i in range(optimal_k)],\n",
        "    'percentage': [segment_sizes[i] / len(customer_segments) * 100 for i in range(optimal_k)]\n",
        "})\n",
        "\n",
        "# Add key metrics to summary\n",
        "for feature in ['n_sessions', 'p_flight_booked', 'p_hotel_booked', 'p_cancellation']:\n",
        "    if feature in display_profiles.columns:\n",
        "        segment_summary[f'avg_{feature}'] = display_profiles[feature].values\n",
        "\n",
        "segment_summary.to_parquet(output_dir / 'segment_summary.parquet', index=False)\n",
        "segment_summary.to_csv(output_dir / 'segment_summary.csv', index=False)\n",
        "\n",
        "# Export detailed profiles\n",
        "display_profiles.to_csv(output_dir / 'segment_profiles_detailed.csv')\n",
        "\n",
        "print(f\"âœ… Segmentation results exported to {output_dir}\")\n",
        "print(f\"   â€¢ segment_assignments.parquet: {len(segment_assignments):,} customers\")\n",
        "print(f\"   â€¢ segment_summary.parquet: {len(segment_summary)} segments\")\n",
        "print(f\"   â€¢ segment_profiles_detailed.csv: Full feature profiles\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\nðŸ“Š Segmentation Summary:\")\n",
        "print(f\"   â€¢ {optimal_k} customer segments identified\")\n",
        "print(f\"   â€¢ {len(available_features)} features used for clustering\")\n",
        "print(f\"   â€¢ Silhouette score: {silhouette_score(X_scaled, cluster_labels):.3f}\")\n",
        "print(f\"   â€¢ Most balanced segment: {segment_sizes.min():,} - {segment_sizes.max():,} customers\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
